{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb9ffc5",
   "metadata": {},
   "source": [
    "# Project work, part 4\n",
    "Sara Hørte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4686130d",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "GitHub repo link: \n",
    "https://github.com/sarahorte/ind320project.git\n",
    "\n",
    "Streamlit app link: \n",
    "https://ind320project.streamlit.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fceb9b3",
   "metadata": {},
   "source": [
    "### Log\n",
    "I began by familiarizing myself with the Open-Meteo API (https://open-meteo.com/en/docs) to determine how to fetch the weather data I needed. I also identified the latitude and longitude coordinates for the cities representing each Norwegian price area. Using this information, I implemented a function to retrieve hourly weather data and tested it successfully on Bergen for 2019. This provided a foundation for integrating live weather data into the application instead of relying on static CSV files.\n",
    "\n",
    "Next, I developed functions for detecting outliers and anomalies in the weather data. I implemented both SPC-based outlier detection for temperature series and Local Outlier Factor (LOF) for precipitation. While testing these functions on Bergen, I found selecting appropriate parameters challenging, as their optimal values depend on the data characteristics. Nevertheless, the functions worked as intended, providing both visualizations and summary statistics, and I designed them to allow easy parameter adjustments as I gain more experience.\n",
    "\n",
    "Following this, I focused on time series analysis techniques. I implemented Seasonal-Trend decomposition using LOESS (STL) and a spectrogram analysis to explore patterns in Elhub electricity production data. To do this efficiently, I reused and adapted code from a previous assignment, ensuring it could handle the Elhub data structure. Choosing parameters for STL and the spectrogram proved difficult, and I realized that interpreting the spectrogram plots meaningfully requires a deeper understanding of frequency-domain patterns in production data.\n",
    "\n",
    "Once the analysis functions were in place, I turned to integrating them into the Streamlit application. I reorganized the app structure and created skeletons for the new pages. I updated existing pages to fetch weather data directly from the API rather than static files, ensuring that the data tables and interactive plots dynamically reflected the selected price area. I then developed the new “Outlier & Anomaly” page (page B), reusing the functions from the notebook. To maintain clarity and functionality, I included the entire functions at the start of the script.\n",
    "\n",
    "Finally, I created the “STL & Spectrogram” page (page A). Here, users can select a production group and adjust analysis parameters interactively. I ensured the data preparation accounted for duplicates by summing production values when multiple entries existed for the same timestamp. This allowed the STL and spectrogram functions to work reliably on hourly production data. Overall, the development process involved iterative testing, parameter tuning, and careful data preparation to ensure that the application provides meaningful insights into both weather and energy production patterns.\n",
    "\n",
    "For convenience, I reused the selected price area from the Energy page across all subsequent pages, though in the future I think it might be more user-friendly to allow the user to choose a price area individually on each page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed753b8e",
   "metadata": {},
   "source": [
    "### AI usage\n",
    "AI was used extensively throughout this project, primarily through ChatGPT and GitHub Copilot in VS Code. I leveraged AI to generate code suggestions, adapt examples from lectures, and refine solutions for specific tasks. For instance, when implementing the Local Outlier Factor method, I combined code snippets from lectures with AI-generated suggestions, then iteratively adjusted and tested the code until it functioned correctly.\n",
    "\n",
    "I also used AI to interpret error messages and propose potential fixes. By testing different solutions suggested by ChatGPT, I was able to identify the most effective approach. Additionally, AI assisted in generating initial visualizations, which I later fine-tuned to achieve the desired appearance. For parameter selection in the various analysis functions, ChatGPT provided guidance, which was helpful as a starting point, though understanding the underlying concepts is essential for making meaningful choices.\n",
    "\n",
    "The interactive nature of the Streamlit app made it easy to experiment with different parameters, and AI guidance accelerated this process. Beyond coding, I also used ChatGPT to refine and improve the wording of both the project log and the AI usage section itself, ensuring clarity and readability.\n",
    "\n",
    "Overall, AI proved to be a valuable tool for both code development and documentation, complementing my own understanding and enabling more efficient problem-solving."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
